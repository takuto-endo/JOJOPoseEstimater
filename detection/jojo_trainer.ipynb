{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"jojo_trainer.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MQtXBAzw9mJp","executionInfo":{"status":"ok","timestamp":1636615259286,"user_tz":-540,"elapsed":1041,"user":{"displayName":"Endo Takuto","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04918638090957286957"}}},"source":["#  jojo_trainer.ipynb\n","#  3.モデルの学習を行う"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"QviXlRT_1Hme","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636615299643,"user_tz":-540,"elapsed":40366,"user":{"displayName":"Endo Takuto","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04918638090957286957"}},"outputId":"68eda315-8c6f-403f-9715-3d7a687de8ae"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"IL0LLAyv9ox3"},"source":["import numpy as np\n","import pandas as pd\n","import random\n","import sys\n","sys.path.append(\"/content/drive/MyDrive/jojo_poser/src\")\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.init as init\n","!pip install torchinfo\n","from torchinfo import summary\n","\n","from image_loader import *\n","from models import *\n","\n","torch.manual_seed(1)\n","np.random.seed(1)\n","random.seed(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e5DYXOg41F0q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636607513908,"user_tz":-540,"elapsed":320,"user":{"displayName":"Endo Takuto","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04918638090957286957"}},"outputId":"c5b2809f-7170-4a1c-ae1a-449b27fa6969"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"使用されるデバイス: \",device)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["使用されるデバイス:  cuda\n"]}]},{"cell_type":"code","metadata":{"id":"W5QDtppu1F0r"},"source":["LABELS = [\"Buccellati\", \"Dio\", \"Giorno\", \"Highway-Star\", \"Jo-suke\", \"Jo-taro\",\n","            \"Kakyoin\", \"Kira\", \"Kishibe\", \"Polnareff\", \"Trish\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_McH8d7f1F0s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636607518280,"user_tz":-540,"elapsed":232,"user":{"displayName":"Endo Takuto","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04918638090957286957"}},"outputId":"0b9b7222-04bc-419a-b3cd-46a1af794694"},"source":["#  画像の読み込み\n","im_rows = 256\n","im_cols = 256\n","\n","#  Dataを取得\n","root_path = \"/content/drive/MyDrive/jojo_poser\"\n","train_img_path_list, train_labels = data_loder(root_path, \"train\")\n","valid_img_path_list, valid_labels = data_loder(root_path, \"valid\")\n","\n","#  Datasetを作成\n","tr_data = PreprocessJOJO(train_img_path_list, train_labels, \"train\", im_rows, im_cols)\n","val_data = PreprocessJOJO(valid_img_path_list, valid_labels, \"valid\", im_rows, im_cols)\n","print('訓練データのサイズ: ', tr_data.__len__())\n","print('検証データのサイズ: ', val_data.__len__())\n","\n","#  DataLorderを作成\n","batch_size = 12\n","tr_batch = data.DataLoader(\n","    tr_data,                #  訓練用data\n","    batch_size = batch_size,#  ミニバッチのサイズ\n","    shuffle = True,         #  シャッフルして抽出\n","    )\n","val_batch = data.DataLoader(\n","    val_data,               #  検証用data\n","    batch_size = batch_size,#  ミニバッチのサイズ\n","    shuffle = False,        #  シャッフルはせずに抽出\n","    )\n","print('訓練データのミニバッチの個数: ', tr_batch.__len__())\n","print('検証データのミニバッチの個数: ', val_batch.__len__())\n","\n","#  DataLoaderをdictにまとめる\n","dataloaders_dict = {\"train\":tr_batch, \"valid\":val_batch}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["訓練データのサイズ:  559\n","検証データのサイズ:  110\n","訓練データのミニバッチの個数:  47\n","検証データのミニバッチの個数:  10\n"]}]},{"cell_type":"code","metadata":{"id":"-FDwg3z71F0t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636607527259,"user_tz":-540,"elapsed":6000,"user":{"displayName":"Endo Takuto","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04918638090957286957"}},"outputId":"39eb1ab3-df8a-4c8f-a59f-049a2bf56fea"},"source":["#  訓練用のDataLorderをイテレーターに変換\n","batch_iterator = iter(dataloaders_dict[\"valid\"])\n","#  最初のミニバッチを取り出す\n","images, labels = next(batch_iterator)\n","print('ミニバッチのイメージの形状: ',images.size())\n","print('ミニバッチのラベルの形状: ',len(labels))\n","print('labels[0]の形状: ',labels[0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ミニバッチのイメージの形状:  torch.Size([12, 3, 256, 256])\n","ミニバッチのラベルの形状:  12\n","labels[0]の形状:  tensor(0)\n"]}]},{"cell_type":"code","metadata":{"id":"mcIkyZAj1F0t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636607531987,"user_tz":-540,"elapsed":1760,"user":{"displayName":"Endo Takuto","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04918638090957286957"}},"outputId":"2f5fdb88-4176-4a68-a3d4-a7f3a504f572"},"source":["#   モデルのインスタンス作成\n","net = JOJO_classifier('train', len(LABELS))\n","#  vggモデルの学習済みの重みを適用\n","vgg_weights = torch.load(root_path+'/weights/vgg16_reducedfc.pth')\n","net.vgg.load_state_dict(vgg_weights)\n","print(\"[model vgg] weights is applied.\")\n","#  denseモデルの重みを初期化\n","if isinstance(net.dense, nn.Linear):\n","    init.kaiming_normal_(net.dense.weight.data)\n","    if net.dense.bias is not None:\n","        init.constant_(net.dense.bias, 0.0)\n","\n","print(net)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[model vgg] weights is applied.\n","JOJO_classifier(\n","  (vgg): ModuleList(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n","    (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n","    (32): ReLU(inplace=True)\n","    (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n","    (34): ReLU(inplace=True)\n","  )\n","  (dense): ModuleList(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=262144, out_features=512, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.4, inplace=False)\n","    (4): Linear(in_features=512, out_features=32, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Dropout(p=0.2, inplace=False)\n","    (7): Linear(in_features=32, out_features=11, bias=True)\n","    (8): Softmax(dim=1)\n","  )\n",")\n"]}]},{"cell_type":"code","metadata":{"id":"GU0lBj4l1F0u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636607538193,"user_tz":-540,"elapsed":3019,"user":{"displayName":"Endo Takuto","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04918638090957286957"}},"outputId":"8f5ff799-8c63-4768-de25-708b0d05b45b"},"source":["summary(\n","    net,\n","    input_size = (batch_size, 3, im_rows, im_cols),\n","    col_names=[\"input_size\",\"output_size\",\"num_params\"])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","0\n","1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]},{"output_type":"stream","name":"stdout","text":["2\n","3\n","4\n","5\n","6\n","7\n","8\n"]},{"output_type":"execute_result","data":{"text/plain":["===================================================================================================================\n","Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n","===================================================================================================================\n","JOJO_classifier                          --                        --                        --\n","├─ModuleList: 1-1                        --                        --                        --\n","├─ModuleList: 1-2                        --                        --                        --\n","├─ModuleList: 1-1                        --                        --                        --\n","│    └─Conv2d: 2-1                       [12, 3, 256, 256]         [12, 64, 256, 256]        1,792\n","│    └─ReLU: 2-2                         [12, 64, 256, 256]        [12, 64, 256, 256]        --\n","│    └─Conv2d: 2-3                       [12, 64, 256, 256]        [12, 64, 256, 256]        36,928\n","│    └─ReLU: 2-4                         [12, 64, 256, 256]        [12, 64, 256, 256]        --\n","│    └─MaxPool2d: 2-5                    [12, 64, 256, 256]        [12, 64, 128, 128]        --\n","│    └─Conv2d: 2-6                       [12, 64, 128, 128]        [12, 128, 128, 128]       73,856\n","│    └─ReLU: 2-7                         [12, 128, 128, 128]       [12, 128, 128, 128]       --\n","│    └─Conv2d: 2-8                       [12, 128, 128, 128]       [12, 128, 128, 128]       147,584\n","│    └─ReLU: 2-9                         [12, 128, 128, 128]       [12, 128, 128, 128]       --\n","│    └─MaxPool2d: 2-10                   [12, 128, 128, 128]       [12, 128, 64, 64]         --\n","│    └─Conv2d: 2-11                      [12, 128, 64, 64]         [12, 256, 64, 64]         295,168\n","│    └─ReLU: 2-12                        [12, 256, 64, 64]         [12, 256, 64, 64]         --\n","│    └─Conv2d: 2-13                      [12, 256, 64, 64]         [12, 256, 64, 64]         590,080\n","│    └─ReLU: 2-14                        [12, 256, 64, 64]         [12, 256, 64, 64]         --\n","│    └─Conv2d: 2-15                      [12, 256, 64, 64]         [12, 256, 64, 64]         590,080\n","│    └─ReLU: 2-16                        [12, 256, 64, 64]         [12, 256, 64, 64]         --\n","│    └─MaxPool2d: 2-17                   [12, 256, 64, 64]         [12, 256, 32, 32]         --\n","│    └─Conv2d: 2-18                      [12, 256, 32, 32]         [12, 512, 32, 32]         1,180,160\n","│    └─ReLU: 2-19                        [12, 512, 32, 32]         [12, 512, 32, 32]         --\n","│    └─Conv2d: 2-20                      [12, 512, 32, 32]         [12, 512, 32, 32]         2,359,808\n","│    └─ReLU: 2-21                        [12, 512, 32, 32]         [12, 512, 32, 32]         --\n","│    └─Conv2d: 2-22                      [12, 512, 32, 32]         [12, 512, 32, 32]         2,359,808\n","│    └─ReLU: 2-23                        [12, 512, 32, 32]         [12, 512, 32, 32]         --\n","│    └─MaxPool2d: 2-24                   [12, 512, 32, 32]         [12, 512, 16, 16]         --\n","│    └─Conv2d: 2-25                      [12, 512, 16, 16]         [12, 512, 16, 16]         2,359,808\n","│    └─ReLU: 2-26                        [12, 512, 16, 16]         [12, 512, 16, 16]         --\n","│    └─Conv2d: 2-27                      [12, 512, 16, 16]         [12, 512, 16, 16]         2,359,808\n","│    └─ReLU: 2-28                        [12, 512, 16, 16]         [12, 512, 16, 16]         --\n","│    └─Conv2d: 2-29                      [12, 512, 16, 16]         [12, 512, 16, 16]         2,359,808\n","│    └─ReLU: 2-30                        [12, 512, 16, 16]         [12, 512, 16, 16]         --\n","│    └─MaxPool2d: 2-31                   [12, 512, 16, 16]         [12, 512, 16, 16]         --\n","│    └─Conv2d: 2-32                      [12, 512, 16, 16]         [12, 1024, 16, 16]        4,719,616\n","│    └─ReLU: 2-33                        [12, 1024, 16, 16]        [12, 1024, 16, 16]        --\n","│    └─Conv2d: 2-34                      [12, 1024, 16, 16]        [12, 1024, 16, 16]        1,049,600\n","│    └─ReLU: 2-35                        [12, 1024, 16, 16]        [12, 1024, 16, 16]        --\n","├─ModuleList: 1-2                        --                        --                        --\n","│    └─Flatten: 2-36                     [12, 1024, 16, 16]        [12, 262144]              --\n","│    └─Linear: 2-37                      [12, 262144]              [12, 512]                 134,218,240\n","│    └─ReLU: 2-38                        [12, 512]                 [12, 512]                 --\n","│    └─Dropout: 2-39                     [12, 512]                 [12, 512]                 --\n","│    └─Linear: 2-40                      [12, 512]                 [12, 32]                  16,416\n","│    └─ReLU: 2-41                        [12, 32]                  [12, 32]                  --\n","│    └─Dropout: 2-42                     [12, 32]                  [12, 32]                  --\n","│    └─Linear: 2-43                      [12, 32]                  [12, 11]                  363\n","│    └─Softmax: 2-44                     [12, 11]                  [12, 11]                  --\n","===================================================================================================================\n","Total params: 154,718,923\n","Trainable params: 154,718,923\n","Non-trainable params: 0\n","Total mult-adds (G): 260.08\n","===================================================================================================================\n","Input size (MB): 9.44\n","Forward/backward pass size (MB): 1749.08\n","Params size (MB): 618.88\n","Estimated Total Size (MB): 2377.39\n","==================================================================================================================="]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"HR8oB5Nl1F0v"},"source":["#  損失関数及びオプティマイザーの作成\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.dense.parameters(),\n","                lr = 0.05)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X0T59dOg1F0w"},"source":["\n","def train(net, dataloaders_dict, criterion, optimizer, num_epochs):\n","    '''\n","    Parameters:\n","        net(object): VGG+Dense モデル\n","        datalorders_dict(dict(object)): DataLorder\n","        criterion(object): 損失関数\n","        optimizer(object): オプティマイザー\n","        num_epochs(int): 学習回数\n","    '''\n","    \n","    net.to(device)\n","    torch.backends.cudnn.benchmark = True\n","    \n","    iteration = 1 #  イテレーション(ステップ)カウンター\n","    epoch_train_loss = 0.0 #  訓練1エポックごとの損失和\n","    epoch_val_loss = 0.0 #  検証1エポックごとの損失和\n","    logs = [] #  損失のログを記録するリスト\n","    \n","    for epoch in range(num_epochs):\n","        print('----------------------------------------------------')\n","        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n","        print('----------------------------------------------------')\n","\n","        for phase in [\"train\",\"valid\"]:\n","\n","            if phase==\"train\":\n","                #  モデルを訓練モードに\n","                net.train()\n","            else:\n","                if((epoch+1)%10 == 0):\n","                    net.eval()#  モデルを検証モードに\n","                    print(\"----------------------------------------------------\")\n","                    print(\"----- validation mode -----\")\n","                else:\n","                    continue\n","                    \n","            #  1ステップにおけるミニバッチを使用した学習または検証\n","            #  データローダーをイテレートしてミニバッチを抽出\n","            for images, labels in dataloaders_dict[phase]:\n","                print(\"labels\",labels)#  ================================== test!!!!\n","                #  画像データにデバイスを割り当てる\n","                images = images.to(device)\n","                #  教師データをデバイスを割り当てる\n","                labels = labels.to(device)\n","\n","                #  optimizerが保持する勾配を0で初期化\n","                optimizer.zero_grad()\n","\n","                #  順伝搬(forward)とバックプロパゲーション(訓練時)\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    #  順伝播(forward)\n","                    outputs = net(images)\n","                    print(\"outputs: \",outputs.data)#  ================================== test!!!!\n","                    print(\"outputs: \",outputs.data.max(1)[1])#  ================================== test!!!!\n","                    #  labelの損失平均\n","                    loss = criterion(outputs, labels)\n","                    print(\"loss: \",loss.item())#  ================================== test!!!!\n","                    \n","                    #  訓練時はバックプロパゲーションによるパラメーター更新を行う\n","                    if phase == 'train':\n","                        loss.backward()  #  バックプロパゲーション\n","\n","                        # 勾配降下法の更新式を適用してバイアス、重みを更新\n","                        optimizer.step()\n","\n","                        # ミニバッチを10個処理(10ステップ)ごとに損失を出力\n","                        if (iteration % 10 == 0):\n","                            #  ステップ, 損失を出力\n","                            print('step( {} )  loss: {:.4f}'.format(iteration, loss.item()))\n","\n","                        # エポックの損失をepoch_train_lossに加算する\n","                        epoch_train_loss += loss.item()\n","                        # ステップ数を1増やす\n","                        iteration += 1\n","\n","                    # 検証モードでは順伝播後の損失の記録のみを行う\n","                    else:\n","                        epoch_val_loss += loss.item()\n","                        \n","        # epochのphaseごとのlossと正解率\n","        print('---------------------------------------')\n","        # 訓練データの損失と検証データの損失を出力\n","        print('train_loss: {:.4f} - val_loss(Every 10 epochs): {:.4f}'.format(epoch_train_loss, epoch_val_loss))\n","\n","        # エポックごとに損失をdictオブジェクトに保存\n","        log_epoch = {'epoch': epoch+1,\n","                     'train_loss': epoch_train_loss,\n","                     'val_loss': epoch_val_loss}\n","        # ログのリストに追加\n","        logs.append(log_epoch)\n","\n","        # 訓練時の損失和を0で初期化\n","        epoch_train_loss = 0.0\n","        # 検証時の損失和を0で初期化\n","        epoch_val_loss = 0.0\n","        \n","        # 1エポック終了ごとにモデルのパラメーター値を保存\n","        if ((epoch+1) % 10 == 0):\n","            torch.save(\n","                net.state_dict(),\n","                root_path + '/weights/jojo_weights' + str(epoch+1) + '.pth')\n","            print('--saved weights--')\n","    # ログのリストをデータフレームに変換\n","    df = pd.DataFrame(logs)\n","    # ログファイルに保存\n","    df.to_csv(root_path + '/outputs/epoch_loss.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8TpbxuzW1F0y","colab":{"base_uri":"https://localhost:8080/","height":447},"executionInfo":{"status":"error","timestamp":1636607378827,"user_tz":-540,"elapsed":11875,"user":{"displayName":"Endo Takuto","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04918638090957286957"}},"outputId":"558a7aea-eb9e-4bac-c1f8-b0cd2419ecfc"},"source":["#  学習\n","num_epochs = 10#  最終は50\n","train(net,\n","      dataloaders_dict,\n","      criterion,\n","      optimizer,\n","      num_epochs=num_epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------\n","Epoch 1/10\n","----------------------------------------------------\n","labels tensor([ 4,  2,  6,  1,  3,  0,  8,  0, 10,  3,  8,  0])\n","outputs:  tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n","loss:  2.459707498550415\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-b0eb6bda9065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       num_epochs=num_epochs)\n\u001b[0m","\u001b[0;32m<ipython-input-14-5d4252f62490>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, dataloaders_dict, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m#  1ステップにおけるミニバッチを使用した学習または検証\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m#  データローダーをイテレートしてミニバッチを抽出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#  ================================== test!!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;31m#  画像データにデバイスを割り当てる\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/jojo_poser/src/image_loader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m正解label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \"\"\"\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpull_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/jojo_poser/src/image_loader.py\u001b[0m in \u001b[0;36mpull_item\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# 画像ファイルを読む\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_path_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#  色空間をRGBに\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# サイズ変更\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    899\u001b[0m         \"\"\"\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"nIUxZ2_WMmUv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PDXZyrPcMmnK"},"source":["#  画像の読み込み\n","im_rows = 256\n","im_cols = 256\n","\n","#  Dataを取得\n","root_path = \"/content/drive/MyDrive/jojo_poser\"\n","valid_imgs, valid_labels = data_loder(root_path,\"valid\", im_rows, im_cols)\n","val_data = PreprocessJOJO(valid_imgs, valid_labels, \"valid\")\n","#  DataLorderを作成\n","batch_size = 1\n","val_batch = data.DataLoader(\n","    val_data,               #  検証用data\n","    batch_size = batch_size,#  ミニバッチのサイズ\n","    shuffle = False,        #  シャッフルはせずに抽出\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qcMPkbLq5cPd","executionInfo":{"status":"ok","timestamp":1636599140685,"user_tz":-540,"elapsed":2845,"user":{"displayName":"Endo Takuto","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04918638090957286957"}},"outputId":"dbc4f412-146b-4268-9859-b496ed7a8261"},"source":["#   モデルのインスタンス作成\n","net = JOJO_classifier('train', len(LABELS))\n","#  vggモデルの学習済みの重みを適用\n","net_weights = torch.load(root_path+'/weights/jojo_weights10.pth')\n","net.load_state_dict(net_weights)\n","print(\"[model net] weights is applied.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[model net] weights is applied.\n"]}]},{"cell_type":"code","metadata":{"id":"FwLXJPHj1F0y"},"source":["soft = nn.Softmax(dim=1)\n","def accuracy(net, val_batch):\n","\n","  all_outputs = []\n","  all_labels = []\n","  for images, labels in val_batch:\n","    print(images)\n","    outputs = soft(net(images))\n","    print(outputs)\n","    all_outputs.append(outputs.data.max(1)[1].item())\n","    all_labels.append(labels.item())\n","    print(\"answer: \",labels.item())\n","    print(\"predict: \", outputs.data.max(1)[1].item())\n","    del images, labels\n","  all_outputs = np.array(all_outputs)\n","  all_labels = np.array(all_labels)\n","  print(\"total accuracy score: \",sum(all_outputs==all_labels)/len(all_labels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8MzCtLDTKjkd"},"source":["accuracy(net, val_batch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AdQPXvLT1B5C"},"source":[""],"execution_count":null,"outputs":[]}]}